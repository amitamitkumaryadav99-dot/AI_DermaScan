# -*- coding: utf-8 -*-
"""Accuracy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kyWJDxLIK9epJbAosbkLwhXXZRpkA294
"""

from google.colab import drive
drive.mount('/content/drive')

import os, shutil

project_path = '/content/drive/MyDrive/Dermalproject'
if not os.path.exists(project_path):
    os.makedirs(project_path)

# Path where original dataset was extracted earlier
source_data = '/content/dermalscan'
dest_data = os.path.join(project_path, 'dermalscan')

# Copy dataset to Drive only once
if os.path.exists(source_data) and not os.path.exists(dest_data):
    shutil.copytree(source_data, dest_data)
    print("Dataset copied to Drive.")
else:
    print("Dataset already exists in Drive or source missing.")

base_dir = dest_data
print("Using dataset from:", base_dir)

import shutil, os

bad_folders = ['drive', '.ipynb_checkpoints']

for bf in bad_folders:
    path = os.path.join(base_dir, bf)
    if os.path.exists(path):
        shutil.rmtree(path)
        print("Removed:", path)

import os
import matplotlib.pyplot as plt

class_counts = {}
for class_name in os.listdir(base_dir):
    class_path = os.path.join(base_dir, class_name)
    if os.path.isdir(class_path):
        class_counts[class_name] = len(os.listdir(class_path))

plt.figure(figsize=(8,5))
plt.bar(class_counts.keys(), class_counts.values())
plt.title("Class Distribution")
plt.ylabel("Count")
plt.show()

print(class_counts)

from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import numpy as np
import matplotlib.pyplot as plt
import os

datagen_viz = ImageDataGenerator(
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

target_class = list(class_counts.keys())[0]
img_name = os.listdir(os.path.join(base_dir, target_class))[0]
img_path = os.path.join(base_dir, target_class, img_name)

img = load_img(img_path, target_size=(224,224))
x = img_to_array(img)
x = x.reshape((1,) + x.shape)

fig, axes = plt.subplots(1, 5, figsize=(15,5))
axes[0].imshow(img)
axes[0].set_title("Original")
axes[0].axis("off")

i = 1
for batch in datagen_viz.flow(x, batch_size=1):
    axes[i].imshow(batch[0].astype("uint8"))
    axes[i].set_title(f"Aug {i}")
    axes[i].axis("off")
    i += 1
    if i >= 5: break

plt.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_height, img_width = 224, 224
batch_size = 16

train_datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model

base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224,224,3))

# Fine-tuning
base_model.trainable = True
for layer in base_model.layers[:-20]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.4)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)
model.summary()

from tensorflow.keras.optimizers import Adam

model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau

checkpoint = ModelCheckpoint(
    '/content/drive/MyDrive/Dermalproject/best_dermal_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=3,
    min_lr=1e-6,
    verbose=1
)

history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=25,
    callbacks=[checkpoint, reduce_lr],
    verbose=1
)

import matplotlib.pyplot as plt

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title("Loss")
plt.legend()

plt.show()

import tensorflow as tf

best_model_path = "/content/drive/MyDrive/Dermalproject/best_dermal_model.h5"
best_model = tf.keras.models.load_model(best_model_path)

loss, accuracy = best_model.evaluate(validation_generator)
print("✔ Final Evaluation Complete")
print(f"✔ Final Loss      : {loss:.4f}")
print(f"✔ Final Accuracy  : {accuracy:.4f}")

import cv2
from tensorflow.keras.applications.efficientnet import preprocess_input

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# MUST MATCH THE ORDER PRINTED BY train_generator.class_indices
classes = ["clear skin", "dark spot", "puffy eyes", "wrinkles"]

def predict_face(face_img):
    face_resized = cv2.resize(face_img, (224, 224))
    face_preprocessed = preprocess_input(face_resized)   # FIXED!
    face_input = np.expand_dims(face_preprocessed, axis=0)

    pred = best_model.predict(face_input)[0]
    predicted_label = classes[np.argmax(pred)]
    confidence = float(np.max(pred)) * 100

    wrinkle_prob = pred[classes.index("wrinkles")] * 100
    age_estimated = int(20 + wrinkle_prob / 2.5)

    return predicted_label, confidence, age_estimated

def analyze_image(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    faces = face_cascade.detectMultiScale(gray, 1.05, 3, minSize=(60,60))

    if len(faces) == 0:
        print("⚠ No face detected.")
        return

    for (x, y, w, h) in faces:
        pad = 25
        x1 = max(0, x - pad)
        y1 = max(0, y - pad)
        x2 = min(img.shape[1], x + w + pad)
        y2 = min(img.shape[0], y + h + pad)

        face_img = img[y1:y2, x1:x2]

        label, conf, age_est = predict_face(face_img)

        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)
        cv2.putText(img, f"{label}", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
        cv2.putText(img, f"{conf:.2f}%", (x1, y2+25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
        cv2.putText(img, f"Age: {age_est}", (x1, y2+55), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

    plt.figure(figsize=(8,8))
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.show()

from google.colab import files
uploaded = files.upload()

img_path = list(uploaded.keys())[0]
analyze_image(img_path)

